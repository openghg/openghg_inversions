from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Iterable, Protocol, TypeVar

import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt
from pytensor.tensor.variable import TensorVariable
import xarray as xr

from openghg_inversions.models.priors import parse_prior, PriorArgs
from openghg_inversions.models.setup import sigma_freq_indicies


def sum_outputs(components: Iterable[HasOutput]) -> TensorVariable:
    """Sum the output variables of a list of components."""
    return sum(component.output for component in components)


MCT = TypeVar("MCT", bound="ModelComponent")


class ModelComponent(ABC):
    component_name: str
    _component_registry: dict = {}
    _name: str
    _model: pm.Model | None = None

    @classmethod
    def __init_subclass__(cls):
        """Register ModelComponents by name, for lookup by model config."""
        ModelComponent._component_registry[cls.component_name] = cls

    @abstractmethod
    def build(self, *args, **kwargs) -> None:
        """Construct a (sub)model for the component.

        This should set the values of `self.model`.

        If called within another `with pm.Model` context, the model
        will be a sub-model of the parent model. Variables and data in submodels
        (including those generated by `ModelComponent`) are propagated to the parent
        model.

        This mechanism allows PyMC to check if the components (sub-models) are consistent
        with the parent model.
        """
        pass

    @property
    def name(self) -> str:
        return self._name

    @name.setter
    def name(self, name: str) -> None:
        self._name = name

    @property
    def model(self) -> pm.Model:
        if self._model is None:
            raise AttributeError("model for this component has not been built yet.")
        return self._model

    @model.setter
    def model(self, model_: pm.Model) -> None:
        self._model = model_

    def __getitem__(self, name: str, /) -> Any:
        """Access model variables directly from ModelComponent."""
        if self.model is None:
            raise AttributeError(f"Cannot access variable {name}; this component has not been built yet.")
        return self.model[f"{self.name}::{name}"]

    def get(self, name: str, default: Any = None) -> Any:
        try:
            result = self[name]
        except KeyError:
            result = default
        return result

class HasOutput(Protocol):
    @property
    @abstractmethod
    def output(self) -> TensorVariable: ...


class LinearForwardComponent(ModelComponent):
    """Linear Component of forward model.

    Given a "H" matrix and a prior distribution, LinearForwardComponent.build()
    creates a random variable "x" with the given prior and outputs a deterministic
    quantity mu = H * x.

    The name of the component will be prepended to any variables in this model, so these
    variables can be accessed by names: `<name>::x` and `<name>::mu`.
    """

    component_name = "linear_forward_component"

    # TODO: component registry and staticmethod to sum up components
    # this method should check that output coords are aligned...
    def __init__(
        self,
        name: str,
        h_matrix: xr.DataArray | np.ndarray,
        prior_args: PriorArgs,
        input_coords: xr.DataArray | np.ndarray | None = None,
        output_dim: str = "nmeasure",
        output_coords: xr.DataArray | np.ndarray | None = None,
    ) -> None:
        """Create LinearForwardComponent object.

        Args:
            name: name of this component.
            h_matrix: matrix mapping (unobserved) inputs to (observed) outputs.
            prior_args: PriorArgs to specify prior for input variable
            input_dims: coordinates to use for input variable. Default coordinates are integers starting at 0.
            output_dim: name of output dimension; default is "nmeasure"
            output_dims: coordinates to use for output variable. Default coordinates are integers starting at 0.

        Returns:
            None.
        """
        super().__init__()
        self.name = (
            name  # TODO: add class level code to make names automatically/fix name conflicts, e.g. counter
        )

        self.h_matrix = h_matrix
        self.h_matrix_values = h_matrix if isinstance(h_matrix, np.ndarray) else h_matrix.values

        self.input_dim = f"nx_{self.name}"
        self.output_dim = output_dim

        # TODO: if h_matrix is DataArray, use its coordinates?
        input_coords = input_coords or np.arange(self.h_matrix_values.shape[1])

        if len(input_coords) != self.h_matrix_values.shape[1]:
            raise ValueError(
                f"Length of specified input coordinates is not equal to the number of rows of the given H matrix."
            )

        self.input_coords = {self.input_dim: input_coords}

        output_coords = output_coords or np.arange(self.h_matrix_values.shape[0])

        if len(output_coords) != self.h_matrix_values.shape[0]:
            raise ValueError(
                f"Length of specified output coordinates is not equal to the number of columns of the given H matrix."
            )

        self.output_coords = {self.output_dim: output_coords}

        self.prior_args = prior_args


    def coords(self) -> dict:
        return {**self.input_coords, **self.output_coords}

    def build(self) -> None:
        self.model = pm.Model(
            name=self.name, coords=self.coords()
        )  # name used to distinguish variables created by this component

        with self.model:
            x = parse_prior("x", self.prior_args, dims=self.input_dim)
            hx = pm.Data("h", self.h_matrix, dims=(self.output_dim, self.input_dim))
            pm.Deterministic("mu", pt.dot(hx, x), dims=self.output_dim)

    @property
    def output(self) -> TensorVariable:
        return self.model["mu"]


class Flux(LinearForwardComponent):
    component_name = "flux"


class BoundaryConditions(LinearForwardComponent):
    component_name = "bc"


class Offset(ModelComponent):
    component_name = "offset"

    def __init__(
        self,
        site_indicator: np.ndarray,
        prior_args: PriorArgs,
        output_dim: str = "nmeasure",
        name: str | None = None
    ) -> None:
        super().__init__()

        if name is not None:
            self.name = f"{name}_offset"
        else:
            self.name = "offset"

        self.site_indicator = site_indicator
        self.offset_matrix = pd.get_dummies(site_indicator, drop_first=True, dtype=int).values

        self.input_dim = "offset_site_number"

        if len(uniq := np.unique(self.site_indicator)) < 2:
            raise ValueError("Cannot add offset for inversion with less than 2 sites.")
        else:
            self.input_coord = uniq[1:]

        self.output_dim = output_dim

        self.prior_args = prior_args

    def coords(self) -> dict:
        result = {
            self.output_dim: np.arange(len(self.site_indicator)),
            self.input_dim: self.input_coord,
        }
        return result

    def build(self) -> None:
        self.model = pm.Model(
            name=self.name, coords=self.coords()
        )  # name used to distinguish variables created by this component

        with self.model:
            x = parse_prior("x", self.prior_args, dims=self.input_dim)
            hx = pm.Data("h", self.offset_matrix, dims=(self.output_dim, self.input_dim))
            pm.Deterministic("mu", pt.dot(hx, x), dims=self.output_dim)

    @property
    def output(self) -> TensorVariable:
        return self.model["mu"]


class Baseline(ModelComponent):
    component_name = "baseline"

    def __init__(self, bc: BoundaryConditions | None = None, offset: Offset | None = None) -> None:
        super().__init__()
        self.name = "baseline"

        # components
        self.child_components = []

        if bc is not None:
            self.child_components.append(bc)

        if offset is not None:
            self.child_components.append(offset)

    def __bool__(self) -> bool:
        return bool(self.child_components)

    def __getattr__(self, name: str) -> Any:
        for child in self.child_components:
            try:
                return getattr(child, name)
            except AttributeError:
                continue
        raise AttributeError(f"Attribute {name} not found in Baseline {self.name} or its child components.")

    def build(self) -> None:
        self.model = pm.Model(name=self._name)

        with self.model:
            for child in self.child_components:
                child.build()

            if self.child_components:
                pm.Deterministic("mu", sum_outputs(self.child_components), dims=self.output_dim)

    @property
    def output(self) -> TensorVariable:
        return self.model["mu"]


class ForwardModel(ModelComponent):
    component_name = "forward_model"

    def __init__(self, flux: Flux, baseline: Baseline | None = None) -> None:
        super().__init__()
        self.name = "forward"

        # components
        self.child_components = []
        self.child_components.append(flux)  # empty list followed by append is to trick mypy...

        if baseline:  # baseline evaluates to False if there is no offset and no bc
            self.child_components.append(baseline)

    def __getattr__(self, name: str) -> Any:
        for child in self.child_components:
            try:
                return getattr(child, name)
            except AttributeError:
                continue
        raise AttributeError(f"Attribute {name} not found in ForwardModel {self.name} or its child components.")

    def build(self) -> None:
        self.model = pm.Model(name=self._name)

        with self.model:
            for child in self.child_components:
                child.build()

            pm.Deterministic("mu", sum_outputs(self.child_components), dims=self.output_dim)

    @property
    def output(self) -> TensorVariable:
        return self.model["mu"]


class RHIMELikelihood(ModelComponent):
    """Likelihood for RHIME model."""

    component_name = "rhime_likelihood"

    def __init__(
        self,
        y_obs: np.ndarray,
        error: np.ndarray,
        sigma_prior: PriorArgs,
        site_indicator: np.ndarray,
        min_error: np.ndarray | float = 0.0,
        pollution_events_from_obs: bool = True,
        no_model_error: bool = False,
        sigma_freq: str | None = None,
        y_time: np.ndarray | None = None,
        sigma_per_site: bool = True,
        sites: list[str] | None = None,
        name: str = "likelihood",
    ) -> None:
        super().__init__()
        self.name = name

        self.y_obs = y_obs
        self.error = error

        self.sigma_prior = sigma_prior

        if sigma_freq is not None:
            if y_time is None:
                raise ValueError("If `sigma_freq` is not None, then `y_time` must be provided.")
            sigma_freq_index = sigma_freq_indicies(y_time, sigma_freq)
        else:
            sigma_freq_index = np.zeros_like(y_obs, dtype=int)

        self.site_indicator = site_indicator
        self.sigma_freq_index = sigma_freq_index
        self.sigma_per_site = sigma_per_site

        self.sites = sites

        if isinstance(min_error, float) or (isinstance(min_error, np.ndarray) and min_error.ndim == 0):
            self.min_error = min_error * np.ones_like(y_obs)
        else:
            self.min_error = min_error

        self.pollution_events_from_obs = pollution_events_from_obs
        self.no_model_error = no_model_error

    def coords(self) -> dict:
        result = {
            "nmeasure": np.arange(len(self.y_obs)),
            "sites": self.sites if self.sites is not None else np.unique(self.site_indicator),
            "nsigma_time": np.unique(self.sigma_freq_index),
            "nsigma_site": np.unique(self.site_indicator) if self.sigma_per_site else [0],
        }
        return result

    def build(self, forward: ForwardModel) -> None:
        self.model = pm.Model(name=self.name, coords=self.coords())

        with self.model as likelihood:
            y_obs = pm.Data("y_obs", self.y_obs, dims="nmeasure")
            error = pm.Data("error", self.error, dims="nmeasure")
            min_error = pm.Data("min_error", self.min_error, dims="nmeasure")

            sigma = parse_prior("sigma", self.sigma_prior, dims=("nsigma_site", "nsigma_time"))

            try:
                baseline = forward.model["baseline::mu"]
            except KeyError:
                baseline = None

            mu_flux = forward.model["flux::mu"]

            if self.pollution_events_from_obs is True:
                if baseline is not None:
                    pollution_event = pt.abs(y_obs - baseline)
                else:
                    pollution_event = pt.abs(y_obs) + 1e-6 * pt.mean(
                        y_obs
                    )  # small non-zero term to prevent NaNs
            else:
                pollution_event = pt.abs(mu_flux)

            # convert siteindicator into a site indexer
            if self.sigma_per_site:
                sites = self.site_indicator.astype(int)
            else:
                sites = np.zeros_like(self.site_indicator).astype(int)

            pollution_event_scaled_error = pollution_event * sigma[sites, self.sigma_freq_index]

            if self.no_model_error is True:
                # need some small non-zero value to avoid sampling problems
                mean_obs = pt.mean(y_obs)
                small_amount = 1e-12 * mean_obs
                eps = pt.maximum(pt.abs(error), small_amount)  # type: ignore
            else:
                eps = pt.maximum(pt.sqrt(error**2 + pollution_event_scaled_error**2), min_error)  # type: ignore

            epsilon = pm.Deterministic("epsilon", eps, dims="nmeasure")

            mu = forward.output

            pm.Normal("y", mu=mu, sigma=epsilon, observed=y_obs, dims="nmeasure")
